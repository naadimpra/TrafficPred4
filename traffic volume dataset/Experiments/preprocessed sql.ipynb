{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-27T08:27:26.340445500Z",
     "start_time": "2023-12-27T08:27:19.380632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              date_time  air_pollution_index   humidity  \\\n",
      "date_time                                                                 \n",
      "2017-05-18 00:00:00 2017-05-18 00:00:00           133.000000  60.666667   \n",
      "2017-05-18 01:00:00 2017-05-18 01:00:00           190.500000  56.000000   \n",
      "2017-05-18 02:00:00 2017-05-18 02:00:00            98.666667  49.000000   \n",
      "2017-05-18 03:00:00 2017-05-18 03:00:00           147.000000  60.000000   \n",
      "2017-05-18 04:00:00 2017-05-18 04:00:00           156.666667  75.000000   \n",
      "...                                 ...                  ...        ...   \n",
      "2018-09-30 19:00:00 2018-09-30 19:00:00           176.000000  21.000000   \n",
      "2018-09-30 20:00:00 2018-09-30 20:00:00           214.000000  95.000000   \n",
      "2018-09-30 21:00:00 2018-09-30 21:00:00           173.000000  63.000000   \n",
      "2018-09-30 22:00:00 2018-09-30 22:00:00            21.000000  57.000000   \n",
      "2018-09-30 23:00:00 2018-09-30 23:00:00           116.000000  70.000000   \n",
      "\n",
      "                     wind_speed  wind_direction  visibility_in_miles  \\\n",
      "date_time                                                              \n",
      "2017-05-18 00:00:00         1.0            18.0             3.000000   \n",
      "2017-05-18 01:00:00         1.0           351.0             1.500000   \n",
      "2017-05-18 02:00:00         1.0            27.0             2.000000   \n",
      "2017-05-18 03:00:00         2.0            36.0             4.000000   \n",
      "2017-05-18 04:00:00         2.0            78.0             5.333333   \n",
      "...                         ...             ...                  ...   \n",
      "2018-09-30 19:00:00         4.0           345.0             4.000000   \n",
      "2018-09-30 20:00:00         8.0           280.0             6.000000   \n",
      "2018-09-30 21:00:00         4.0           238.0             1.000000   \n",
      "2018-09-30 22:00:00         8.0           268.0             7.000000   \n",
      "2018-09-30 23:00:00         8.0           328.0             6.000000   \n",
      "\n",
      "                     dew_point  temperature  rain_p_h  snow_p_h  clouds_all  \\\n",
      "date_time                                                                     \n",
      "2017-05-18 00:00:00   3.000000       285.15       0.0       0.0        90.0   \n",
      "2017-05-18 01:00:00   1.500000       284.79       0.0       0.0        90.0   \n",
      "2017-05-18 02:00:00   2.000000       284.29       0.0       0.0        90.0   \n",
      "2017-05-18 03:00:00   4.000000       283.51       0.0       0.0        90.0   \n",
      "2017-05-18 04:00:00   5.333333       283.09       0.0       0.0        90.0   \n",
      "...                        ...          ...       ...       ...         ...   \n",
      "2018-09-30 19:00:00   4.000000       283.45       0.0       0.0        75.0   \n",
      "2018-09-30 20:00:00   6.000000       282.76       0.0       0.0        90.0   \n",
      "2018-09-30 21:00:00   1.000000       282.73       0.0       0.0        90.0   \n",
      "2018-09-30 22:00:00   7.000000       282.09       0.0       0.0        90.0   \n",
      "2018-09-30 23:00:00   6.000000       282.12       0.0       0.0        90.0   \n",
      "\n",
      "                     traffic_volume is_holiday  weather_type  \\\n",
      "date_time                                                      \n",
      "2017-05-18 00:00:00               0       None       Drizzle   \n",
      "2017-05-18 01:00:00               0       None          Mist   \n",
      "2017-05-18 02:00:00               0       None       Drizzle   \n",
      "2017-05-18 03:00:00               0       None       Drizzle   \n",
      "2017-05-18 04:00:00               0       None       Drizzle   \n",
      "...                             ...        ...           ...   \n",
      "2018-09-30 19:00:00               0       None        Clouds   \n",
      "2018-09-30 20:00:00               0       None        Clouds   \n",
      "2018-09-30 21:00:00               0       None  Thunderstorm   \n",
      "2018-09-30 22:00:00               0       None        Clouds   \n",
      "2018-09-30 23:00:00               0       None        Clouds   \n",
      "\n",
      "                         weather_description  \n",
      "date_time                                     \n",
      "2017-05-18 00:00:00  light intensity drizzle  \n",
      "2017-05-18 01:00:00     heavy intensity rain  \n",
      "2017-05-18 02:00:00                  drizzle  \n",
      "2017-05-18 03:00:00     heavy intensity rain  \n",
      "2017-05-18 04:00:00     heavy intensity rain  \n",
      "...                                      ...  \n",
      "2018-09-30 19:00:00            broken clouds  \n",
      "2018-09-30 20:00:00          overcast clouds  \n",
      "2018-09-30 21:00:00   proximity thunderstorm  \n",
      "2018-09-30 22:00:00          overcast clouds  \n",
      "2018-09-30 23:00:00          overcast clouds  \n",
      "\n",
      "[11986 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define custom scorer for MAPE\n",
    "def mape_scorer(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    non_zero_mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[non_zero_mask] - y_pred[non_zero_mask]) / y_true[non_zero_mask])) * 100\n",
    "\n",
    "# Load the dataset\n",
    "df_raw = pd.read_csv('../Test.csv')\n",
    "\n",
    "# Convert the 'date_time' column to datetime and sort the dataset\n",
    "df_raw['date_time'] = pd.to_datetime(df_raw['date_time'])\n",
    "df_raw.sort_values('date_time', inplace=True)\n",
    "\n",
    "# Extracting non-numeric columns\n",
    "non_numeric_cols = ['is_holiday', 'weather_type', 'weather_description']\n",
    "\n",
    "# Group by 'date_time' and aggregate: mean for numeric columns, mode for non-numeric columns\n",
    "agg_funcs = {col: 'mean' for col in df_raw.columns if col not in non_numeric_cols}\n",
    "agg_funcs.update({col: lambda x: x.mode()[0] if not x.mode().empty else np.nan for col in non_numeric_cols})\n",
    "\n",
    "df_aggregated = df_raw.groupby('date_time').agg(agg_funcs)\n",
    "\n",
    "# Drop duplicate rows\n",
    "df_aggregated.drop_duplicates(inplace=True)\n",
    "\n",
    "# Add 'traffic_volume' column with 0 values before 'is_holiday'\n",
    "df_aggregated.insert(loc=df_aggregated.columns.get_loc('is_holiday'), column='traffic_volume', value=0)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "print(df_aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df_aggregated.to_csv('testsql.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T08:27:26.481446700Z",
     "start_time": "2023-12-27T08:27:26.344455900Z"
    }
   },
   "id": "7872a5881960142e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e6f694f9601fe1b9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
