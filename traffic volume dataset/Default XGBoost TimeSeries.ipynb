{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define custom scorer for MAPE\n",
    "def mape_scorer(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    non_zero_mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[non_zero_mask] - y_pred[non_zero_mask]) / y_true[non_zero_mask])) * 100\n",
    "\n",
    "# Make scorers from custom scoring functions\n",
    "mape = make_scorer(mape_scorer, greater_is_better=False)\n",
    "\n",
    "class TqdmRandomizedSearchCV(RandomizedSearchCV):\n",
    "    def __init__(self, estimator, param_distributions, *, n_iter=10, scoring=None, n_jobs=None,\n",
    "                 refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs',\n",
    "                 random_state=None, error_score=np.nan, return_train_score=False):\n",
    "        super().__init__(\n",
    "            estimator=estimator, param_distributions=param_distributions, n_iter=n_iter,\n",
    "            scoring=scoring, n_jobs=n_jobs, refit=refit, cv=cv, verbose=verbose,\n",
    "            pre_dispatch=pre_dispatch, random_state=random_state, error_score=error_score,\n",
    "            return_train_score=return_train_score)\n",
    "        \n",
    "    def fit(self, X, y, **fit_params):\n",
    "        with tqdm(total=self.n_iter, desc=\"RandomizedSearchCV Progress\") as self._tqdm:\n",
    "            return super().fit(X, y, **fit_params)\n",
    "\n",
    "    def _run_search(self, evaluate_candidates):\n",
    "        \"\"\" Use tqdm with RandomizedSearchCV \"\"\"\n",
    "        super()._run_search(evaluate_candidates)\n",
    "\n",
    "# Load the dataset\n",
    "df_raw = pd.read_csv('Train.csv')\n",
    "\n",
    "# Convert the 'date_time' column to datetime and sort the dataset\n",
    "df_raw['date_time'] = pd.to_datetime(df_raw['date_time'])\n",
    "df_raw.sort_values('date_time', inplace=True)\n",
    "df_raw.set_index('date_time', inplace=True)\n",
    "\n",
    "# Convert 'is_holiday' from categorical to binary (1 for any holiday, 0 for non-holiday)\n",
    "df_raw['is_holiday'] = df_raw['is_holiday'].apply(lambda x: 0 if x == 'None' else 1)\n",
    "\n",
    "# Extract hour from the 'date_time' column\n",
    "df_raw['hour'] = df_raw.index.hour\n",
    "\n",
    "# One-hot encode categorical features\n",
    "df = pd.get_dummies(df_raw, columns=['weather_type', 'weather_description'], drop_first=True)\n",
    "\n",
    "# Feature engineering: create lagged and rolling features\n",
    "target = 'traffic_volume'\n",
    "for i in range(1, 4):\n",
    "    df[f'traffic_volume_lag_{i}'] = df[target].shift(i)\n",
    "df['traffic_volume_rolling_mean'] = df[target].rolling(window=3).mean().shift(1)\n",
    "df['traffic_volume_rolling_std'] = df[target].rolling(window=3).std().shift(1)\n",
    "\n",
    "# Remove rows with NaN values resulting from lagged features\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Split the dataset into features and the target\n",
    "X = df.drop(target, axis=1)\n",
    "y = df[target]\n",
    "\n",
    "# Split the dataset into numerical and categorical features for scaling\n",
    "X_numerical = df.drop(list(df.filter(regex='is_holiday')), axis=1)\n",
    "X_categorical = df.filter(regex='is_holiday')\n",
    "\n",
    "# Scale the numerical features\n",
    "scaler = StandardScaler()\n",
    "X_numerical_scaled = scaler.fit_transform(X_numerical)\n",
    "\n",
    "# Combine scaled numerical and categorical features\n",
    "X_scaled = np.concatenate((X_numerical_scaled, X_categorical), axis=1)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "total_samples = X_scaled.shape[0]\n",
    "split_index = int(total_samples * 0.9)\n",
    "\n",
    "X_train = X_scaled[:split_index]\n",
    "y_train = y.iloc[:split_index]\n",
    "X_test = X_scaled[split_index:]\n",
    "y_test = y.iloc[split_index:]\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "xgboost_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Define the parameter distributions for RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.5, 1],\n",
    "    'reg_alpha': [0, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Update the scoring parameter with a dictionary of metrics\n",
    "scoring = {\n",
    "    'RMSE': 'neg_root_mean_squared_error',\n",
    "    'MSE': 'neg_mean_squared_error',\n",
    "    'MAE': 'neg_mean_absolute_error',\n",
    "    'MAPE': mape\n",
    "}\n",
    "\n",
    "# Create a TimeSeriesSplit cross-validator\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Initialize the TqdmRandomizedSearchCV object with the time series cross-validator\n",
    "random_search = TqdmRandomizedSearchCV(\n",
    "    estimator=xgboost_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=100,\n",
    "    scoring=scoring,\n",
    "    refit='RMSE',\n",
    "    cv=tscv,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the random search to the scaled data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_parameters = random_search.best_params_\n",
    "print(f\"Best parameters found: {best_parameters}\")\n",
    "\n",
    "# Train the best model on the scaled data\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the model using time series cross-validation on the training data\n",
    "train_rmse_list = []\n",
    "train_mae_list = []\n",
    "train_r2_list = []\n",
    "train_mape_list = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X_train):\n",
    "    X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "    best_model.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_train_fold = best_model.predict(X_train_fold)\n",
    "\n",
    "    rmse_train_fold = np.sqrt(mean_squared_error(y_train_fold, y_pred_train_fold))\n",
    "    mae_train_fold = mean_absolute_error(y_train_fold, y_pred_train_fold)\n",
    "    r2_train_fold = r2_score(y_train_fold, y_pred_train_fold)\n",
    "    mape_train_fold = mape_scorer(y_train_fold, y_pred_train_fold)\n",
    "\n",
    "    train_rmse_list.append(rmse_train_fold)\n",
    "    train_mae_list.append(mae_train_fold)\n",
    "    train_r2_list.append(r2_train_fold)\n",
    "    train_mape_list.append(mape_train_fold)\n",
    "\n",
    "# Print the average metrics over all folds for training data\n",
    "print(\"Average Training Metrics:\")\n",
    "print(f\"RMSE: {np.mean(train_rmse_list)}\")\n",
    "print(f\"MAE: {np.mean(train_mae_list)}\")\n",
    "print(f\"R-squared: {np.mean(train_r2_list)}\")\n",
    "print(f\"MAPE: {np.mean(train_mape_list)}\")\n",
    "\n",
    "# Evaluate the model using metrics on the validation data\n",
    "y_pred_val = best_model.predict(X_train[test_index])\n",
    "\n",
    "# Calculate the metrics for the validation set\n",
    "rmse_val = np.sqrt(mean_squared_error(y_train[test_index], y_pred_val))\n",
    "mae_val = mean_absolute_error(y_train[test_index], y_pred_val)\n",
    "r2_val = r2_score(y_train[test_index], y_pred_val)\n",
    "mape_val = mape_scorer(y_train[test_index], y_pred_val)\n",
    "\n",
    "# Print the metrics for the validation set\n",
    "print(\"\\nMetrics for Validation Set:\")\n",
    "print(f\"RMSE: {rmse_val}\")\n",
    "print(f\"MAE: {mae_val}\")\n",
    "print(f\"R-squared: {r2_val}\")\n",
    "print(f\"MAPE: {mape_val}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
